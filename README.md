# Healthcare-RCM-Pipeline

## Overview
The **Healthcare-RCM-Pipeline** is a scalable data pipeline designed for **Healthcare Revenue Cycle Management (RCM)**, with a focus on **claims processing and denials management**. This project begins with **file-based batch processing (MVP)** and will evolve into a real-time **HL7 and EDI API-driven system** using **Kafka, Spark, and Airflow**.

## Architecture Diagram
![Healthcare RCM Pipeline Architecture](docs/architecture.png)

## Features
- âœ… **MVP (Phase 1):** Batch processing for **EDI 837 (Claims), EDI 835 (Denials), Retro, Invoice, and Cross Files**.
- ðŸ”„ **Phase 2:** Integration of **HL7 interfaces & APIs** for real-time ingestion.
- ðŸš€ **Phase 3:** Full **event-driven automation** for claims submissions & denials resubmission.
- ðŸ“Š **Data Storage:** Supports **Snowflake, PostgreSQL, and NoSQL Databases**.
- ðŸ“ˆ **Monitoring & Analytics:** **Grafana, Prometheus, and R1 Hub Analytics (SSRS)**.
- ðŸ¤– **Machine Learning (Optional):** Predict **denial risks & automate claim corrections**.

## Tech Stack
| Category               | Tools & Technologies |
|-----------------------|----------------------|
| **Data Ingestion**   | Kafka, REST API, SFTP |
| **Processing & ETL**  | Apache Spark, PySpark, Airflow, Pandas |
| **Storage & Querying**| Snowflake, PostgreSQL, NoSQL (MongoDB) |
| **Machine Learning**  | MLflow, AWS SageMaker (Optional) |
| **Monitoring & Alerts** | Prometheus, Grafana, SSRS |

## Repository Structure
```
ðŸ“‚ Healthcare-RCM-Pipeline
â”‚â”€â”€ ðŸ“‚ ingestion           # Data ingestion (File-based, API, Streaming)
â”‚â”€â”€ ðŸ“‚ processing          # Airflow DAGs, Spark transformations
â”‚â”€â”€ ðŸ“‚ storage             # SQL scripts, data loaders
â”‚â”€â”€ ðŸ“‚ analytics           # SQL queries, dashboards
â”‚â”€â”€ ðŸ“‚ ml_model (Optional) # Denial risk prediction model
â”‚â”€â”€ ðŸ“‚ api                 # Claim submission & resubmission APIs
â”‚â”€â”€ ðŸ“‚ data_samples        # Sample EDI 837, 835 files
â”‚â”€â”€ README.md              # Documentation
â”‚â”€â”€ requirements.txt       # Dependencies
â”‚â”€â”€ .gitignore             # Ignore unnecessary files
```

## Getting Started
### Prerequisites
- Python 3.8+
- Kafka
- Apache Airflow
- Apache Spark
- PostgreSQL / Snowflake
- AWS S3 (Optional)

### Installation
1. Clone the repository:
   ```bash
   cd Healthcare-RCM-Pipeline
   git clone https://github.com/ishi3012/healthcare-rcm-pipeline.git
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Set up Airflow and Kafka:
   ```bash
   docker-compose up
   ```

## Contribution Guidelines
We welcome contributions! Please open an issue or submit a pull request with any improvements or feature additions.

## License
This project is licensed under the MIT License.

---
ðŸ’¡ **Future Enhancements:** Integration of real-time analytics, automated claim correction workflows, and predictive modeling for **denials reduction**.

